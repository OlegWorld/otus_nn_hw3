{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.395049504950492 9.199035423364862\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "mean = np.mean(y_train)\n",
    "std = np.std(y_train)\n",
    "\n",
    "y_train = (y_train - mean) / std\n",
    "y_test = (y_test - mean) / std\n",
    "\n",
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 512)               7168      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 532,993\n",
      "Trainable params: 532,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(13,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse',\n",
    "              optimizer='adam',\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 363 samples, validate on 41 samples\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 0s 870us/step - loss: 0.2239 - mean_squared_error: 0.2239 - val_loss: 0.1887 - val_mean_squared_error: 0.1887\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 832us/step - loss: 0.2475 - mean_squared_error: 0.2475 - val_loss: 0.2352 - val_mean_squared_error: 0.2352\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 753us/step - loss: 0.2041 - mean_squared_error: 0.2041 - val_loss: 0.1826 - val_mean_squared_error: 0.1826\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 808us/step - loss: 0.1875 - mean_squared_error: 0.1875 - val_loss: 0.1791 - val_mean_squared_error: 0.1791\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 892us/step - loss: 0.1843 - mean_squared_error: 0.1843 - val_loss: 0.2166 - val_mean_squared_error: 0.2166\n",
      "Train on 363 samples, validate on 41 samples\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 0s 885us/step - loss: 0.2030 - mean_squared_error: 0.2030 - val_loss: 0.1250 - val_mean_squared_error: 0.1250\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 858us/step - loss: 0.2108 - mean_squared_error: 0.2108 - val_loss: 0.1580 - val_mean_squared_error: 0.1580\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 758us/step - loss: 0.1901 - mean_squared_error: 0.1901 - val_loss: 0.1705 - val_mean_squared_error: 0.1705\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 916us/step - loss: 0.2349 - mean_squared_error: 0.2349 - val_loss: 0.1262 - val_mean_squared_error: 0.1262\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 844us/step - loss: 0.2325 - mean_squared_error: 0.2325 - val_loss: 0.2057 - val_mean_squared_error: 0.2057\n",
      "Train on 363 samples, validate on 41 samples\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 0s 979us/step - loss: 0.1981 - mean_squared_error: 0.1981 - val_loss: 0.2305 - val_mean_squared_error: 0.2305\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 815us/step - loss: 0.2218 - mean_squared_error: 0.2218 - val_loss: 0.2370 - val_mean_squared_error: 0.2370\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 858us/step - loss: 0.2189 - mean_squared_error: 0.2189 - val_loss: 0.2156 - val_mean_squared_error: 0.2156\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 802us/step - loss: 0.2242 - mean_squared_error: 0.2242 - val_loss: 0.2452 - val_mean_squared_error: 0.2452\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 823us/step - loss: 0.1813 - mean_squared_error: 0.1813 - val_loss: 0.2319 - val_mean_squared_error: 0.2319\n",
      "Train on 363 samples, validate on 41 samples\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 0s 845us/step - loss: 0.2111 - mean_squared_error: 0.2111 - val_loss: 0.2389 - val_mean_squared_error: 0.2389\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 834us/step - loss: 0.1778 - mean_squared_error: 0.1778 - val_loss: 0.2259 - val_mean_squared_error: 0.2259\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 826us/step - loss: 0.1899 - mean_squared_error: 0.1899 - val_loss: 0.2273 - val_mean_squared_error: 0.2273\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 845us/step - loss: 0.1996 - mean_squared_error: 0.1996 - val_loss: 0.2250 - val_mean_squared_error: 0.2250\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.1999 - mean_squared_error: 0.1999 - val_loss: 0.2338 - val_mean_squared_error: 0.2338\n",
      "Train on 364 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 0s 901us/step - loss: 0.1614 - mean_squared_error: 0.1614 - val_loss: 0.1784 - val_mean_squared_error: 0.1784\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 0s 957us/step - loss: 0.1848 - mean_squared_error: 0.1848 - val_loss: 0.1556 - val_mean_squared_error: 0.1556\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 0s 878us/step - loss: 0.1991 - mean_squared_error: 0.1991 - val_loss: 0.1388 - val_mean_squared_error: 0.1388\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 0s 861us/step - loss: 0.2002 - mean_squared_error: 0.2002 - val_loss: 0.1642 - val_mean_squared_error: 0.1642\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 0s 816us/step - loss: 0.1965 - mean_squared_error: 0.1965 - val_loss: 0.1116 - val_mean_squared_error: 0.1116\n",
      "Train on 364 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 0s 772us/step - loss: 0.1664 - mean_squared_error: 0.1664 - val_loss: 0.2726 - val_mean_squared_error: 0.2726\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 0s 871us/step - loss: 0.1990 - mean_squared_error: 0.1990 - val_loss: 0.2687 - val_mean_squared_error: 0.2687\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 0s 802us/step - loss: 0.1663 - mean_squared_error: 0.1663 - val_loss: 0.2498 - val_mean_squared_error: 0.2498\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 0s 814us/step - loss: 0.2011 - mean_squared_error: 0.2011 - val_loss: 0.2763 - val_mean_squared_error: 0.2763\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 0s 862us/step - loss: 0.1855 - mean_squared_error: 0.1855 - val_loss: 0.2337 - val_mean_squared_error: 0.2337\n",
      "Train on 364 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 0s 875us/step - loss: 0.2189 - mean_squared_error: 0.2189 - val_loss: 0.1434 - val_mean_squared_error: 0.1434\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 0s 828us/step - loss: 0.2216 - mean_squared_error: 0.2216 - val_loss: 0.1472 - val_mean_squared_error: 0.1472\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 0s 753us/step - loss: 0.1993 - mean_squared_error: 0.1993 - val_loss: 0.1435 - val_mean_squared_error: 0.1435\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 0s 781us/step - loss: 0.2070 - mean_squared_error: 0.2070 - val_loss: 0.1920 - val_mean_squared_error: 0.1920\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 0s 742us/step - loss: 0.1900 - mean_squared_error: 0.1900 - val_loss: 0.1540 - val_mean_squared_error: 0.1540\n",
      "Train on 364 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 0s 743us/step - loss: 0.1536 - mean_squared_error: 0.1536 - val_loss: 0.4704 - val_mean_squared_error: 0.4704\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 0s 817us/step - loss: 0.1819 - mean_squared_error: 0.1819 - val_loss: 0.6613 - val_mean_squared_error: 0.6613\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 0s 764us/step - loss: 0.1649 - mean_squared_error: 0.1649 - val_loss: 0.4486 - val_mean_squared_error: 0.4486\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 0s 771us/step - loss: 0.1449 - mean_squared_error: 0.1449 - val_loss: 0.5234 - val_mean_squared_error: 0.5234\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 0s 739us/step - loss: 0.1922 - mean_squared_error: 0.1922 - val_loss: 0.5951 - val_mean_squared_error: 0.5951\n",
      "Train on 364 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 0s 780us/step - loss: 0.1764 - mean_squared_error: 0.1764 - val_loss: 0.2374 - val_mean_squared_error: 0.2374\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 0s 741us/step - loss: 0.2154 - mean_squared_error: 0.2154 - val_loss: 0.2912 - val_mean_squared_error: 0.2912\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 0s 776us/step - loss: 0.2006 - mean_squared_error: 0.2006 - val_loss: 0.2743 - val_mean_squared_error: 0.2743\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 0s 811us/step - loss: 0.1933 - mean_squared_error: 0.1933 - val_loss: 0.1663 - val_mean_squared_error: 0.1663\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 0s 735us/step - loss: 0.2056 - mean_squared_error: 0.2056 - val_loss: 0.1367 - val_mean_squared_error: 0.1367\n",
      "Train on 364 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 0s 746us/step - loss: 0.1742 - mean_squared_error: 0.1742 - val_loss: 0.1327 - val_mean_squared_error: 0.1327\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 0s 766us/step - loss: 0.1968 - mean_squared_error: 0.1968 - val_loss: 0.1187 - val_mean_squared_error: 0.1187\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364/364 [==============================] - 0s 736us/step - loss: 0.1842 - mean_squared_error: 0.1842 - val_loss: 0.1348 - val_mean_squared_error: 0.1348\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 0s 834us/step - loss: 0.2163 - mean_squared_error: 0.2163 - val_loss: 0.1123 - val_mean_squared_error: 0.1123\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 0s 744us/step - loss: 0.2095 - mean_squared_error: 0.2095 - val_loss: 0.1149 - val_mean_squared_error: 0.1149\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "for train, test in kf.split(x_train, y_train):\n",
    "    model.fit(x_train[train], y_train[train], \n",
    "              batch_size=batch_size, \n",
    "              epochs=epochs, \n",
    "              verbose=1, \n",
    "              validation_data=(x_train[test], y_train[test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3987903583283518\n",
      "Test accuracy: 0.3987903583283518\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
